{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Lesson 8: First Machine Learning Model ðŸ¤–**\n",
        "\n"
      ],
      "metadata": {
        "id": "PV6u_d1lCuAt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our goal is to build a model that can predict a game's Genre based on its sales in different regions.\n"
      ],
      "metadata": {
        "id": "7CVfPfWdGkOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Machine Learning Workflow\n",
        "The standard workflow involves these key steps:\n",
        "\n",
        "1. Prepare the Data: Load the data and separate it into features and the target.\n",
        "\n",
        "2. Split the Data: Divide the data into a training set and a testing set.\n",
        "\n",
        "3. Train the Model: \"Fit\" the model to the training data.\n",
        "\n",
        "4. Evaluate the Model: Test the model's performance on the unseen testing data."
      ],
      "metadata": {
        "id": "c6VrGKzXDPG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1 & 2: Prepare and Split the Data\n"
      ],
      "metadata": {
        "id": "EsDe3CI4HCCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "csv_data = \"\"\"Rank,Name,Platform,Year,Genre,Publisher,NA_Sales,EU_Sales,JP_Sales,Other_Sales,Global_Sales\n",
        "1,Wii Sports,Wii,2006,Sports,Nintendo,41.49,29.02,3.77,8.46,82.74\n",
        "2,Super Mario Bros.,NES,1985,Platform,Nintendo,29.08,3.58,6.81,0.77,40.24\n",
        "3,Mario Kart Wii,Wii,2008,Racing,Nintendo,15.85,12.88,3.79,3.31,35.82\n",
        "4,Wii Sports Resort,Wii,2009,Sports,Nintendo,15.75,11.01,3.28,2.96,33\n",
        "5,Pokemon Red/Pokemon Blue,GB,1996,Role-Playing,Nintendo,11.27,8.89,10.22,1,31.37\n",
        "6,Tetris,GB,1989,Puzzle,Nintendo,23.2,2.26,4.22,0.58,30.26\n",
        "7,New Super Mario Bros.,DS,2006,Platform,Nintendo,11.38,9.23,6.5,2.9,30.01\n",
        "8,Wii Play,Wii,2006,Misc,Nintendo,14.03,9.2,2.93,2.85,29.02\n",
        "9,New Super Mario Bros. Wii,Wii,2009,Platform,Nintendo,14.59,7.06,4.7,2.26,28.62\n",
        "10,Duck Hunt,NES,1984,Shooter,Nintendo,26.93,0.63,0.28,0.47,28.31\n",
        "11,Nintendogs,DS,2005,Simulation,Nintendo,9.07,11,1.93,2.75,24.76\n",
        "12,Mario Kart DS,DS,2005,Racing,Nintendo,9.81,7.57,4.13,1.92,23.42\n",
        "13,Pokemon Gold/Pokemon Silver,GB,2000,Role-Playing,Nintendo,9,6.18,7.2,0.71,23.1\n",
        "14,Wii Fit,Wii,2008,Sports,Nintendo,8.94,8.03,3.6,2.15,22.72\n",
        "15,Wii Fit Plus,Wii,2009,Sports,Nintendo,9.09,8.59,2.53,1.79,22\n",
        "16,Kinect Adventures!,X360,2010,Misc,Microsoft Game Studios,14.97,4.94,0.24,1.67,21.82\n",
        "17,Grand Theft Auto V,PS3,2013,Action,Take-Two Interactive,7.01,9.27,0.97,4.14,21.4\n",
        "18,Grand Theft Auto: San Andreas,PS2,2004,Action,Take-Two Interactive,9.43,0.4,0.41,10.57,20.81\n",
        "19,Super Mario World,SNES,1990,Platform,Nintendo,12.78,3.75,3.54,0.55,20.61\n",
        "20,Brain Age: Train Your Brain in Minutes a Day,DS,2006,Misc,Nintendo,4.75,9.26,4.16,2.05,20.22\n",
        "\"\"\"\n",
        "vgsales_df = pd.read_csv(io.StringIO(csv_data))\n",
        "features=['NA_Sales','EU_Sales','JP_Sales']\n",
        "target='Genre'\n",
        "X=vgsales_df[features]\n",
        "y=vgsales_df[target]\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_train.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrCsbN5hCrlj",
        "outputId": "69371095-1514-4165-dbaf-0bc4be8a1c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (16, 3)\n",
            "X_test shape: (16, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 & 4: Train the Model and Make Predictions"
      ],
      "metadata": {
        "id": "yDSueHo7G7P9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j4wV_QmBhsG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "124be2b3-5303-40f7-d806-41de42fda000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Model's Prediction on the Test Data --- \n",
            "['Racing' 'Shooter' 'Shooter' 'Platform']\n",
            "\n",
            "--- Actual Genres of the Test Data ---\n",
            "['Sports' 'Action' 'Misc' 'Platform']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import io\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "csv_data = \"\"\"Rank,Name,Platform,Year,Genre,Publisher,NA_Sales,EU_Sales,JP_Sales,Other_Sales,Global_Sales\n",
        "1,Wii Sports,Wii,2006,Sports,Nintendo,41.49,29.02,3.77,8.46,82.74\n",
        "2,Super Mario Bros.,NES,1985,Platform,Nintendo,29.08,3.58,6.81,0.77,40.24\n",
        "3,Mario Kart Wii,Wii,2008,Racing,Nintendo,15.85,12.88,3.79,3.31,35.82\n",
        "4,Wii Sports Resort,Wii,2009,Sports,Nintendo,15.75,11.01,3.28,2.96,33\n",
        "5,Pokemon Red/Pokemon Blue,GB,1996,Role-Playing,Nintendo,11.27,8.89,10.22,1,31.37\n",
        "6,Tetris,GB,1989,Puzzle,Nintendo,23.2,2.26,4.22,0.58,30.26\n",
        "7,New Super Mario Bros.,DS,2006,Platform,Nintendo,11.38,9.23,6.5,2.9,30.01\n",
        "8,Wii Play,Wii,2006,Misc,Nintendo,14.03,9.2,2.93,2.85,29.02\n",
        "9,New Super Mario Bros. Wii,Wii,2009,Platform,Nintendo,14.59,7.06,4.7,2.26,28.62\n",
        "10,Duck Hunt,NES,1984,Shooter,Nintendo,26.93,0.63,0.28,0.47,28.31\n",
        "11,Nintendogs,DS,2005,Simulation,Nintendo,9.07,11,1.93,2.75,24.76\n",
        "12,Mario Kart DS,DS,2005,Racing,Nintendo,9.81,7.57,4.13,1.92,23.42\n",
        "13,Pokemon Gold/Pokemon Silver,GB,2000,Role-Playing,Nintendo,9,6.18,7.2,0.71,23.1\n",
        "14,Wii Fit,Wii,2008,Sports,Nintendo,8.94,8.03,3.6,2.15,22.72\n",
        "15,Wii Fit Plus,Wii,2009,Sports,Nintendo,9.09,8.59,2.53,1.79,22\n",
        "16,Kinect Adventures!,X360,2010,Misc,Microsoft Game Studios,14.97,4.94,0.24,1.67,21.82\n",
        "17,Grand Theft Auto V,PS3,2013,Action,Take-Two Interactive,7.01,9.27,0.97,4.14,21.4\n",
        "18,Grand Theft Auto: San Andreas,PS2,2004,Action,Take-Two Interactive,9.43,0.4,0.41,10.57,20.81\n",
        "19,Super Mario World,SNES,1990,Platform,Nintendo,12.78,3.75,3.54,0.55,20.61\n",
        "20,Brain Age: Train Your Brain in Minutes a Day,DS,2006,Misc,Nintendo,4.75,9.26,4.16,2.05,20.22\n",
        "\"\"\"\n",
        "vgsales_df = pd.read_csv(io.StringIO(csv_data))\n",
        "features=['NA_Sales','EU_Sales','JP_Sales']\n",
        "target='Genre'\n",
        "X=vgsales_df[features]\n",
        "y=vgsales_df[target]\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "model= DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train,y_train)\n",
        "predictions=model.predict(X_test)\n",
        "print(\"--- Model's Prediction on the Test Data --- \")\n",
        "print(predictions)\n",
        "print(\"\\n--- Actual Genres of the Test Data ---\")\n",
        "print(y_test.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Evaluate the Model"
      ],
      "metadata": {
        "id": "TWXDOyikQ19v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import io\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "csv_data = \"\"\"Rank,Name,Platform,Year,Genre,Publisher,NA_Sales,EU_Sales,JP_Sales,Other_Sales,Global_Sales\n",
        "1,Wii Sports,Wii,2006,Sports,Nintendo,41.49,29.02,3.77,8.46,82.74\n",
        "2,Super Mario Bros.,NES,1985,Platform,Nintendo,29.08,3.58,6.81,0.77,40.24\n",
        "3,Mario Kart Wii,Wii,2008,Racing,Nintendo,15.85,12.88,3.79,3.31,35.82\n",
        "4,Wii Sports Resort,Wii,2009,Sports,Nintendo,15.75,11.01,3.28,2.96,33\n",
        "5,Pokemon Red/Pokemon Blue,GB,1996,Role-Playing,Nintendo,11.27,8.89,10.22,1,31.37\n",
        "6,Tetris,GB,1989,Puzzle,Nintendo,23.2,2.26,4.22,0.58,30.26\n",
        "7,New Super Mario Bros.,DS,2006,Platform,Nintendo,11.38,9.23,6.5,2.9,30.01\n",
        "8,Wii Play,Wii,2006,Misc,Nintendo,14.03,9.2,2.93,2.85,29.02\n",
        "9,New Super Mario Bros. Wii,Wii,2009,Platform,Nintendo,14.59,7.06,4.7,2.26,28.62\n",
        "10,Duck Hunt,NES,1984,Shooter,Nintendo,26.93,0.63,0.28,0.47,28.31\n",
        "11,Nintendogs,DS,2005,Simulation,Nintendo,9.07,11,1.93,2.75,24.76\n",
        "12,Mario Kart DS,DS,2005,Racing,Nintendo,9.81,7.57,4.13,1.92,23.42\n",
        "13,Pokemon Gold/Pokemon Silver,GB,2000,Role-Playing,Nintendo,9,6.18,7.2,0.71,23.1\n",
        "14,Wii Fit,Wii,2008,Sports,Nintendo,8.94,8.03,3.6,2.15,22.72\n",
        "15,Wii Fit Plus,Wii,2009,Sports,Nintendo,9.09,8.59,2.53,1.79,22\n",
        "16,Kinect Adventures!,X360,2010,Misc,Microsoft Game Studios,14.97,4.94,0.24,1.67,21.82\n",
        "17,Grand Theft Auto V,PS3,2013,Action,Take-Two Interactive,7.01,9.27,0.97,4.14,21.4\n",
        "18,Grand Theft Auto: San Andreas,PS2,2004,Action,Take-Two Interactive,9.43,0.4,0.41,10.57,20.81\n",
        "19,Super Mario World,SNES,1990,Platform,Nintendo,12.78,3.75,3.54,0.55,20.61\n",
        "20,Brain Age: Train Your Brain in Minutes a Day,DS,2006,Misc,Nintendo,4.75,9.26,4.16,2.05,20.22\n",
        "\"\"\"\n",
        "vgsales_df = pd.read_csv(io.StringIO(csv_data))\n",
        "features=['NA_Sales','EU_Sales','JP_Sales']\n",
        "target='Genre'\n",
        "X=vgsales_df[features]\n",
        "y=vgsales_df[target]\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "model= DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train,y_train)\n",
        "predictions=model.predict(X_test)\n",
        "print(\"--- Model's Prediction on the Test Data --- \")\n",
        "print(predictions)\n",
        "print(\"\\n--- Actual Genres of the Test Data ---\")\n",
        "print(y_test.values)\n",
        "accuracy=accuracy_score(y_test,predictions)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x1zl7nOP6SW",
        "outputId": "4389753b-ca7d-468f-b837-27539f037143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Model's Prediction on the Test Data --- \n",
            "['Racing' 'Shooter' 'Shooter' 'Platform']\n",
            "\n",
            "--- Actual Genres of the Test Data ---\n",
            "['Sports' 'Action' 'Misc' 'Platform']\n",
            "Model Accuracy: 25.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###***Practice Problem: Iris Flower Classification*** ðŸŒ¸\n",
        "Goal: Build a machine learning model to predict the species of an Iris flower based on its sepal and petal measurements."
      ],
      "metadata": {
        "id": "hrrXl2hTmh2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Iris dataset embedded as a string\n",
        "csv_data = \"\"\"sepal_length,sepal_width,petal_length,petal_width,species\n",
        "5.1,3.5,1.4,0.2,Iris-setosa\n",
        "4.9,3.0,1.4,0.2,Iris-setosa\n",
        "4.7,3.2,1.3,0.2,Iris-setosa\n",
        "4.6,3.1,1.5,0.2,Iris-setosa\n",
        "5.0,3.6,1.4,0.2,Iris-setosa\n",
        "5.4,3.9,1.7,0.4,Iris-setosa\n",
        "4.6,3.4,1.4,0.3,Iris-setosa\n",
        "5.0,3.4,1.5,0.2,Iris-setosa\n",
        "4.4,2.9,1.4,0.2,Iris-setosa\n",
        "4.9,3.1,1.5,0.1,Iris-setosa\n",
        "7.0,3.2,4.7,1.4,Iris-versicolor\n",
        "6.4,3.2,4.5,1.5,Iris-versicolor\n",
        "6.9,3.1,4.9,1.5,Iris-versicolor\n",
        "5.5,2.3,4.0,1.3,Iris-versicolor\n",
        "6.5,2.8,4.6,1.5,Iris-versicolor\n",
        "5.7,2.8,4.5,1.3,Iris-versicolor\n",
        "6.3,3.3,4.7,1.6,Iris-versicolor\n",
        "4.9,2.4,3.3,1.0,Iris-versicolor\n",
        "6.6,2.9,4.6,1.3,Iris-versicolor\n",
        "5.2,2.7,3.9,1.4,Iris-versicolor\n",
        "6.3,3.3,6.0,2.5,Iris-virginica\n",
        "5.8,2.7,5.1,1.9,Iris-virginica\n",
        "7.1,3.0,5.9,2.1,Iris-virginica\n",
        "6.3,2.9,5.6,1.8,Iris-virginica\n",
        "6.5,3.0,5.8,2.2,Iris-virginica\n",
        "7.6,3.0,6.6,2.1,Iris-virginica\n",
        "4.9,2.5,4.5,1.7,Iris-virginica\n",
        "7.3,2.9,6.3,1.8,Iris-virginica\n",
        "6.7,2.5,5.8,1.8,Iris-virginica\n",
        "7.2,3.6,6.1,2.5,Iris-virginica\n",
        "\"\"\"\n",
        "\n",
        "iris_df = pd.read_csv(io.StringIO(csv_data))\n",
        "feature=['sepal_length','sepal_width','petal_length','petal_width']\n",
        "target='species'\n",
        "X=iris_df[feature]\n",
        "y=iris_df[target]\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "model=DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train,y_train)\n",
        "predictions=model.predict(X_test)\n",
        "print(f\"The predictions are:\\n {predictions}\")\n",
        "accuracy=accuracy_score(y_test,predictions)\n",
        "print(f\"The accuracy of the current model is {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "HghmDDcORncv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fb49722-7334-47cc-969f-10768a18691e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predictions are:\n",
            " ['Iris-virginica' 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor'\n",
            " 'Iris-setosa' 'Iris-setosa']\n",
            "The accuracy of the current model is 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###***Practice Project: Titanic Survival Prediction*** ðŸš¢\n",
        "Goal: Build a machine learning model that predicts whether a passenger survived the Titanic disaster based on their information (e.g., age, class, sex)."
      ],
      "metadata": {
        "id": "s-wvHO5hmX_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Titanic dataset from a URL\n",
        "titanic_df = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
        "\n",
        "# Get a first look at the data and its issues\n",
        "print(\"--- First 5 Rows ---\")\n",
        "print(titanic_df.head())\n",
        "\n",
        "print(\"\\n--- Dataset Info (Look for missing values and non-numeric columns) ---\")\n",
        "titanic_df.info()\n",
        "titanic_df['Sex']=titanic_df['Sex'].map({'male':0,'female':1})\n",
        "mean_age=titanic_df['Age'].mean()\n",
        "titanic_df['Age']=titanic_df['Age'].fillna(mean_age)\n",
        "print(\"--- Updated DataFrame Info ---\")\n",
        "titanic_df.info()\n",
        "\n",
        "print(\"\\n--- Data after cleaning ---\")\n",
        "print(titanic_df.head())\n",
        "\n",
        "features=['Age','Sex','Pclass']\n",
        "target='Survived'\n",
        "X=titanic_df[features]\n",
        "y=titanic_df[target]\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "model=DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train,y_train)\n",
        "prediction=model.predict(X_test)\n",
        "accuracy=accuracy_score(y_test,prediction)\n",
        "print(f\"Titanic Survival Prediction Model Accuracy: {accuracy*100:2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS6eernlAAxI",
        "outputId": "986921eb-aaaa-44ce-c70c-4e27bc180942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- First 5 Rows ---\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "\n",
            "--- Dataset Info (Look for missing values and non-numeric columns) ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "--- Updated DataFrame Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    int64  \n",
            " 5   Age          891 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(6), object(4)\n",
            "memory usage: 83.7+ KB\n",
            "\n",
            "--- Data after cleaning ---\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name  Sex   Age  SibSp  Parch  \\\n",
            "0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1      0   \n",
            "2                             Heikkinen, Miss. Laina    1  26.0      0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1      0   \n",
            "4                           Allen, Mr. William Henry    0  35.0      0      0   \n",
            "\n",
            "             Ticket     Fare Cabin Embarked  \n",
            "0         A/5 21171   7.2500   NaN        S  \n",
            "1          PC 17599  71.2833   C85        C  \n",
            "2  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3            113803  53.1000  C123        S  \n",
            "4            373450   8.0500   NaN        S  \n",
            "Titanic Survival Prediction Model Accuracy: 77.653631%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Lesson 9: Improving Your Model**"
      ],
      "metadata": {
        "id": "zuXOyJ4asjSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two common ways to improve a model's performance:\n",
        "\n",
        "1. Feature Engineering: Creating better, more informative input features from the data you already have.\n",
        "\n",
        "2. Trying a Different Model: Some models are naturally more powerful or better suited for certain types of problems than others.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZwCJuvnNGZeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering"
      ],
      "metadata": {
        "id": "sxelKsqpHCe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df['Title']=titanic_df['Name'].str.extract(' ([A-za-z]+)\\.',expand=False)\n",
        "titanic_df['Title']=titanic_df['Title'].replace(['Lady','Countess','Capt','Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'],'Rare')\n",
        "titanic_df['Title']=titanic_df['Title'].replace('Mlle','Miss')\n",
        "titanic_df['Title']=titanic_df['Title'].replace('Ms','Miss')\n",
        "titanic_df['Title']=titanic_df['Title'].replace('Mme','Mrs')\n",
        "title_mapping={\n",
        "    \"Mr\":1,\n",
        "    \"Miss\":2,\n",
        "    \"Mrs\":3,\n",
        "    \"Master\":4,\n",
        "    \"Rare\":5\n",
        "}\n",
        "titanic_df['Title']=titanic_df['Title'].map(title_mapping)\n",
        "titanic_df['Title']=titanic_df['Title'].fillna(0)\n",
        "print(\"--- Cleaned Title Column ---\")\n",
        "print(titanic_df['Title'].value_counts())\n",
        "\n",
        "print(\"\\n--- DataFrame Head with New Title Column ---\")\n",
        "print(titanic_df.head())"
      ],
      "metadata": {
        "id": "_-frfse-g0Z4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b0bef6-f7bc-4631-b10e-bfa4d72a02f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Cleaned Title Column ---\n",
            "Title\n",
            "1    517\n",
            "2    185\n",
            "3    126\n",
            "4     40\n",
            "5     23\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- DataFrame Head with New Title Column ---\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name  Sex   Age  SibSp  Parch  \\\n",
            "0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1      0   \n",
            "2                             Heikkinen, Miss. Laina    1  26.0      0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1      0   \n",
            "4                           Allen, Mr. William Henry    0  35.0      0      0   \n",
            "\n",
            "             Ticket     Fare Cabin Embarked  Title  \n",
            "0         A/5 21171   7.2500   NaN        S      1  \n",
            "1          PC 17599  71.2833   C85        C      3  \n",
            "2  STON/O2. 3101282   7.9250   NaN        S      2  \n",
            "3            113803  53.1000  C123        S      3  \n",
            "4            373450   8.0500   NaN        S      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "feature=['Title','Age','Pclass','Sex']\n",
        "target='Survived'\n",
        "X=titanic_df[feature]\n",
        "y=titanic_df[target]\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "model=DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train,y_train)\n",
        "prediction=model.predict(X_test)\n",
        "accuracy=accuracy_score(y_test,prediction)\n",
        "print(f\"The updated accuracy of the new model is :{accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "EDRVC5ZPonm0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "803436cf-8714-49e4-ebf8-243769793437"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The updated accuracy of the new model is :78.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W3EsQ8FwlCoC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}